### 1-3. Gaussian discriminant analysis (Gaussian Naive Bayes) with iris dataset

#Download the dataset
!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv

#Overview the dataset
df3 = pd.read_csv('iris.csv', names=["SepalLength","SepalWidth","PetalLength","PetalWidth","Species"])
df3.head()

#Data preprocessing
df3['SepalLength'] = df3['SepalLength'].astype(float)
df3['SepalWidth'] = df3['SepalWidth'].astype(float)
df3['PetalLength'] = df3['PetalLength'].astype(float)
df3['PetalWidth'] = df3['PetalWidth'].astype(float)
df3['Species'] = df3['Species'].apply(lambda x: 0 if x == "Iris-virginica" else (1 if x=="Iris-versicolor" else 2))
df3.head()

X = df3[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]
y = df3['Species']
print(X.shape)
print(y.shape)


## Goal: Use GDA to predict y (what the species of the flower is) based on given features (SepalLength, SepalWidth, PetalLength, PetalWidth)
❗READ CAREFULLY ⬇
#*   Use the functions we covered in the lab practice
#*   TO-DO:
  #    1.   Split the dataset into training and testing sets (75:25)
  #    2.   Using the training set, compute mean and std for each class and report them (Note that we have three classes (i.e., "Iris-virginica" (0), "Iris-versicolor" (1), "Iris-setosa" (2)))
  #    3.   Using testing set, compute the class probabilities as we did in the lab practice. Report the final prediction labels for each testing sample and testing accuracy.
  #    4.   Again, test again using the following data and report class prediction probabilities of each class and final prediction label
          #   - test=[5.7, 2.9, 4.2, 1.3]


import pandas as pd

# Shuffle dataset
shuffle_df3 = df3.sample(frac=1)

# Define a size for training set
train_size = int(0.75 * len(df3))

# Split dataset
train_set = shuffle_df3[:train_size]
test_set = shuffle_df3[train_size:]


#from lab code
# Split the dataset by class values (i.e., labels), returns a dictionary
def separate_by_class(dataset):
	data_dict = dict()
	for i in range(len(dataset)):
		vector = dataset[i]
		class_value = vector[-1]
		if (class_value not in data_dict):
			data_dict[class_value] = list()
		data_dict[class_value].append(vector)
	return data_dict

from math import sqrt
# compute the standard deviation of a list of numbers
def stdev(numbers):
	avg = mean(numbers)
	variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)
	return sqrt(variance)

# compute the mean of a list of numbers
def mean(numbers):
	return sum(numbers)/float(len(numbers))

# Calculate the mean, stdev and count for each column in a dataset
def mean_std_for_all(dataset):
	summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]
	del(summaries[-1])
	return summaries

def mean_std_per_class(dataset):
  separated = separate_by_class(dataset)
  summaries = dict()
  for class_value, rows in separated.items():
    print(class_value, rows)
    summaries[class_value] = mean_std_for_all(rows)
  return summaries

dataset = np.array(train_set)
summary = mean_std_per_class(dataset)
for label in summary:
	print(label)
	for row in summary[label]:
		print(row)# (mean, std, len)

# use Gaussian PDF to derive the probability
from math import sqrt
from math import pi
from math import exp

# compute the Gaussian probability distribution function (i.e., pdf) for x
def calculate_probability(x, mean, stdev):
	exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))
	return (1 / (sqrt(2 * pi) * stdev)) * exponent

# compute the probabilities of predicting each class for a given row
def calculate_class_probabilities(summaries, row):
  total_rows = sum([summaries[label][0][2] for label in summaries]) # summaries[label][0][2]: length
  probabilities = dict()
  for class_value, class_summaries in summaries.items():
    probabilities[class_value] = summaries[class_value][0][2]/float(total_rows) # prior

    for i in range(len(class_summaries)):
      mean, stdev, count = class_summaries[i]
      probabilities[class_value] *= calculate_probability(row[i], mean, stdev)
  return probabilities

def predict_label(probs):
  return max(probs, key=probs.get)

dataset = np.array(test_set)
summaries = mean_std_per_class(dataset)
# Test with the first row of the dataset
probabilities = calculate_class_probabilities(summaries, dataset[0])
print(probabilities)
print(predict_label(probabilities))
probabilities = calculate_class_probabilities(summaries, dataset[5])
print(probabilities)
print(predict_label(probabilities))

#from kaggle code
summaries = mean_std_per_class(dataset)
test = [5.7, 2.9, 4.2, 1.3]
probabilities = calculate_class_probabilities(summaries, test)
print(probabilities)
print(predict_label(probabilities))
